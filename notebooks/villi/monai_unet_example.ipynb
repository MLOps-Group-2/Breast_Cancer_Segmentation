{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Todo:\n",
    "\n",
    "Dependancies added:\n",
    "\n",
    "- monai\n",
    "- pillow\n",
    "- tensorboard"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e1cc7fb88958d56"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import ArrayDataset, create_test_image_2d, decollate_batch, DataLoader\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandRotate90,\n",
    "    RandSpatialCrop,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:10:08.112771225Z",
     "start_time": "2024-01-16T09:10:05.063965960Z"
    }
   },
   "id": "9fd85e2d0ffcdd9",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.26.3\n",
      "Pytorch version: 2.1.2+cu121\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: /home/<username>/anaconda3/envs/breast_cancer_segmentation/lib/python3.11/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scipy version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 10.2.0\n",
      "Tensorboard version: 2.15.1\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.16.2+cu121\n",
      "tqdm version: 4.66.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.7\n",
      "pandas version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n"
     ]
    }
   ],
   "source": [
    "monai.config.print_config()\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:10:08.177700335Z",
     "start_time": "2024-01-16T09:10:08.114769744Z"
    }
   },
   "id": "381d31741bbac817",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating synthetic data to ./test_data (this may take a while)\n"
     ]
    }
   ],
   "source": [
    "# create a temporary directory and 40 random image, mask pairs\n",
    "tempdir = \"./test_data\"\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    im, seg = create_test_image_2d(224, 224, num_seg_classes=1)\n",
    "    Image.fromarray((im * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"img{i:d}.png\"))\n",
    "    Image.fromarray((seg * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"seg{i:d}.png\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T11:36:05.975069052Z",
     "start_time": "2024-01-09T11:36:05.621434812Z"
    }
   },
   "id": "902445512c07596",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Ingest images from local file storage\n",
    "tempdir = \"../../data/raw/BCSS\"\n",
    "images = sorted(glob(os.path.join(tempdir, \"train\", \"*.png\")))[:40]\n",
    "segs = sorted(glob(os.path.join(tempdir, \"train_mask\", \"*.png\")))[:40]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:10:12.975345971Z",
     "start_time": "2024-01-16T09:10:12.742262437Z"
    }
   },
   "id": "16cedfbdaaabe118",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "40"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:10:15.445847170Z",
     "start_time": "2024-01-16T09:10:15.439682435Z"
    }
   },
   "id": "2fcaad7049780092",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "train_imtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        ScaleIntensity(),\n",
    "        RandSpatialCrop((96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
    "    ]\n",
    ")\n",
    "train_segtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        ScaleIntensity(),\n",
    "        RandSpatialCrop((96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
    "    ]\n",
    ")\n",
    "val_imtrans = Compose([LoadImage(image_only=True, ensure_channel_first=True), ScaleIntensity()])\n",
    "val_segtrans = Compose([LoadImage(image_only=True, ensure_channel_first=True), ScaleIntensity()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:10:24.912346778Z",
     "start_time": "2024-01-16T09:10:24.892483887Z"
    }
   },
   "id": "fae86c65eb835e5",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 96, 96]) torch.Size([10, 1, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "# define array dataset, data loader\n",
    "check_ds = ArrayDataset(images, train_imtrans, segs, train_segtrans)\n",
    "check_loader = DataLoader(check_ds, batch_size=10, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im, seg = monai.utils.misc.first(check_loader)\n",
    "print(im.shape, seg.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:10:26.779042918Z",
     "start_time": "2024-01-16T09:10:26.421167114Z"
    }
   },
   "id": "d19afe93e2f085f1",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create a training data loader\n",
    "train_ds = ArrayDataset(images[:20], train_imtrans, segs[:20], train_segtrans)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())\n",
    "# create a validation data loader\n",
    "val_ds = ArrayDataset(images[-20:], val_imtrans, segs[-20:], val_segtrans)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:11:22.673574415Z",
     "start_time": "2024-01-16T09:11:22.626428716Z"
    }
   },
   "id": "f8aa2505d4ea6764",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T11:59:36.195040994Z",
     "start_time": "2024-01-09T11:59:36.125695399Z"
    }
   },
   "id": "1ebc3274d29458b8",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/10\n",
      "1/5, train_loss: 0.8670\n",
      "2/5, train_loss: 0.7761\n",
      "3/5, train_loss: 0.5840\n",
      "4/5, train_loss: 0.8561\n",
      "5/5, train_loss: 0.6172\n",
      "epoch 1 average loss: 0.7401\n",
      "----------\n",
      "epoch 2/10\n",
      "1/5, train_loss: 0.5887\n",
      "2/5, train_loss: 0.9311\n",
      "3/5, train_loss: 0.5341\n",
      "4/5, train_loss: 0.7677\n",
      "5/5, train_loss: 0.6574\n",
      "epoch 2 average loss: 0.6958\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.3519 best mean dice: 0.3519 at epoch 2\n",
      "----------\n",
      "epoch 3/10\n",
      "1/5, train_loss: 0.7433\n",
      "2/5, train_loss: 0.8635\n",
      "3/5, train_loss: 0.6003\n",
      "4/5, train_loss: 0.6998\n",
      "5/5, train_loss: 0.8209\n",
      "epoch 3 average loss: 0.7456\n",
      "----------\n",
      "epoch 4/10\n",
      "1/5, train_loss: 0.7521\n",
      "2/5, train_loss: 0.6787\n",
      "3/5, train_loss: 0.7968\n",
      "4/5, train_loss: 0.6748\n",
      "5/5, train_loss: 0.5531\n",
      "epoch 4 average loss: 0.6911\n",
      "saved new best metric model\n",
      "current epoch: 4 current mean dice: 0.3800 best mean dice: 0.3800 at epoch 4\n",
      "----------\n",
      "epoch 5/10\n",
      "1/5, train_loss: 0.6639\n",
      "2/5, train_loss: 0.6869\n",
      "3/5, train_loss: 0.7370\n",
      "4/5, train_loss: 0.8204\n",
      "5/5, train_loss: 0.6687\n",
      "epoch 5 average loss: 0.7154\n",
      "----------\n",
      "epoch 6/10\n",
      "1/5, train_loss: 0.9822\n",
      "2/5, train_loss: 0.5842\n",
      "3/5, train_loss: 0.7593\n",
      "4/5, train_loss: 0.7180\n",
      "5/5, train_loss: 0.5521\n",
      "epoch 6 average loss: 0.7191\n",
      "saved new best metric model\n",
      "current epoch: 6 current mean dice: 0.3954 best mean dice: 0.3954 at epoch 6\n",
      "----------\n",
      "epoch 7/10\n",
      "1/5, train_loss: 0.5935\n",
      "2/5, train_loss: 0.6555\n",
      "3/5, train_loss: 0.7455\n",
      "4/5, train_loss: 0.6877\n",
      "5/5, train_loss: 0.8896\n",
      "epoch 7 average loss: 0.7143\n",
      "----------\n",
      "epoch 8/10\n",
      "1/5, train_loss: 0.7679\n",
      "2/5, train_loss: 0.7899\n",
      "3/5, train_loss: 0.8450\n",
      "4/5, train_loss: 0.5529\n",
      "5/5, train_loss: 0.5455\n",
      "epoch 8 average loss: 0.7003\n",
      "saved new best metric model\n",
      "current epoch: 8 current mean dice: 0.4031 best mean dice: 0.4031 at epoch 8\n",
      "----------\n",
      "epoch 9/10\n",
      "1/5, train_loss: 0.7707\n",
      "2/5, train_loss: 0.6634\n",
      "3/5, train_loss: 0.7529\n",
      "4/5, train_loss: 0.7598\n",
      "5/5, train_loss: 0.8692\n",
      "epoch 9 average loss: 0.7632\n",
      "----------\n",
      "epoch 10/10\n",
      "1/5, train_loss: 0.6037\n",
      "2/5, train_loss: 0.7243\n",
      "3/5, train_loss: 0.6573\n",
      "4/5, train_loss: 0.5825\n",
      "5/5, train_loss: 0.7577\n",
      "epoch 10 average loss: 0.6651\n",
      "saved new best metric model\n",
      "current epoch: 10 current mean dice: 0.4153 best mean dice: 0.4153 at epoch 10\n",
      "train completed, best_metric: 0.4153 at epoch: 10\n"
     ]
    }
   ],
   "source": [
    "# start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(10):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{10}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                roi_size = (96, 96)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"best_metric_model_segmentation2d_array.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T11:59:58.434201792Z",
     "start_time": "2024-01-09T11:59:37.722352386Z"
    }
   },
   "id": "1077e9a4e2499ab9",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T12:03:04.509380115Z",
     "start_time": "2024-01-09T12:03:04.422473188Z"
    }
   },
   "id": "bab417d4bef048d2",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e543e38df7faf1b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
